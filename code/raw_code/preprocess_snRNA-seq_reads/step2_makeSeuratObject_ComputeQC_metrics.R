## conda activate r4
## packages for data table processing 
library(here)
library(tidyverse)

## for maddie

## main Seurat package snRNA-seq pacakges
library(Seurat)
library(SeuratDisk)
library(SeuratWrappers)
library(future)

## packages for QC metric computation
library(SingleCellExperiment)
library(scds)
library(flexmix)
library(SoupX)
library(DropletUtils)
library(DropletQC)
library(Matrix)

ss <- function(x, pattern, slot = 1, ...) { 
  sapply(strsplit(x = x, split = pattern, ...), '[', slot) }
options(stringsAsFactors = F)
options(repr.plot.width=11, repr.plot.height=8.5)

#########################################################
# 0) Seurat uses the future package for parallelization
## set to be parallel over 8 cores
plan("multicore", workers = 16)
options(future.globals.maxSize = 20000 * 1024^2)
options(future.rng.onMisuse = 'ignore')

##########################################
# 1) find the files generated by STARsolo 
# files are both raw counts and filtered counts by STARsolo
# these folders should have a barcodes.tsv, genes.tsv, and matrix.mtx files
STARsoloDIR= 'data/raw_data/STARsolo_out'

## find folders where filtered outputs are
STARsolo_filtered_fn = STARsoloDIR %>% 
  list.dirs(full.names = T,recursive = T) %>%
  str_subset('GeneFull') %>% str_subset('filtered$')

## find folders where raw outputs are
STARsolo_raw_fn = STARsoloDIR %>% 
  list.dirs(full.names = T,recursive = T) %>%
  str_subset('GeneFull') %>% str_subset('raw$')

## name the file paths by string matching with regex patterns
## this gets sample names such as C-13114, based on folder naming convention 
names(STARsolo_filtered_fn) = ss(STARsolo_filtered_fn,"(STARsolo_out/)|(.Solo.out)",2)
head(STARsolo_filtered_fn)

names(STARsolo_raw_fn) = ss(STARsolo_raw_fn,"(STARsolo_out/)|(.Solo.out)",2)
head(STARsolo_raw_fn)

## look at files in these directories
(tmp_fn = sapply(c(STARsolo_filtered_fn, STARsolo_raw_fn), list.files, full.names = T))
## files should show barcodes.tsv.gz, features.tsv.gz, and matrix.mtx.gz
parallel::mclapply(unlist(tmp_fn), function(file) 
  if(!grepl('.gz$', file)) R.utils::gzip(file), mc.cores = 16)


##################################
# 2) Ambient RNA removal by SoupX
for(sample in names(STARsolo_raw_fn)){
  de_soup_counts_dn = gsub('filtered','SoupX_counts', STARsolo_filtered_fn[sample])
  if(dir.exists(de_soup_counts_dn)){
    print(paste('SoupX already computed:', de_soup_counts_dn))
  } else{
    print(paste('Reading in counts for:', sample,'.'))
    ## read in the filtered counts and raw counts
    ## https://rawcdn.githack.com/constantAmateur/SoupX/204b602418df12e9fdb4b68775a8b486c6504fe4/inst/doc/pbmcTutorial.html
    toc = Seurat::Read10X(STARsolo_filtered_fn[sample])
    tod = Seurat::Read10X(STARsolo_raw_fn[sample])
    
    ## routine Seurat clustering for SoupX, will be redone later
    ## https://satijalab.org/seurat/articles/essential_commands.html
    print(paste('Processing counts for SoupX.'))
    obj <- CreateSeuratObject(counts = toc) %>%
      NormalizeData(verbose = F) %>%
      FindVariableFeatures(verbose = F) %>%
      ScaleData(verbose = F) %>%
      RunPCA(verbose = F) %>%
      FindNeighbors(verbose = F) %>%
      FindClusters(algorithm = 2, resolution = 0.5, verbose = F)

    ## give SoupX the filtered counts, raw counts, and highly required basic clustering
    print(paste('Estimating ambient RNA w/ SoupX.'))
    sc = SoupChannel(tod, toc)
    sc = setClusters(sc, setNames(obj$seurat_clusters, colnames(obj)))
    sc = autoEstCont(sc, doPlot = F)
    out = adjustCounts(sc, roundToInt=TRUE)
    
    ## adjust filtered cell counts for ambient RNA
    print(paste('Corrected counts output to:', de_soup_counts_dn))
    write10xCounts(de_soup_counts_dn, out, barcodes = ss(colnames(out),'_',2), version = '3')
  }
}


#####################################################
# 3) use STARsolo RNA velocity estimates (spliced vs. unspliced counts)
# to estimate %nuclear reads per cell for DropletQC
## https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02547-0
## https://github.com/powellgenomicslab/DropletQC
STARsolo_fn = STARsoloDIR %>% 
  list.dirs(full.names = T,recursive = T) %>% str_subset('GeneFull$')
names(STARsolo_fn) = ss(STARsolo_fn,"(STARsolo_out/)|(.Solo.out)",2)

## create filenames for nuclear fraction estimate tables
nuclearFractionEstimates_fn = 
  setNames(file.path(STARsolo_fn, 'DropletQC_NuclearFraction.txt.gz'), names(STARsolo_fn))

## for each sample, compute the nuclear fraction
for (sample in names(STARsolo_fn)){
  if(file.exists(nuclearFractionEstimates_fn[sample])){
      print(paste("DropletQC has already been computed for", sample))
  } else{
    print(paste('Reading in velocity counts for:', sample,'.'))
    file = STARsolo_fn[sample]
    
    ## grab the cell barcodes from the velocity counts
    barcodes = file %>% stringr::str_replace('GeneFull', 'Velocyto') %>% 
      file.path('raw/barcodes.tsv.gz') %>% 
      data.table::fread(header = F, col.names = 'barcodes')
    
    ## total the exonic UMI counts per cell
    exon_sum <- file %>% stringr::str_replace('GeneFull', 'Velocyto') %>% 
      file.path('raw/spliced.mtx.gz') %>% Matrix::readMM() %>% Matrix::colSums()
    
    ## total the intron UMI counts per cell
    intron_sum <- file %>%  stringr::str_replace('GeneFull', 'Velocyto') %>% 
      file.path('raw/unspliced.mtx.gz') %>% Matrix::readMM() %>% Matrix::colSums()
    
    ## compute the per-cell nuclear fraction
    nuc_frac = intron_sum / (intron_sum + exon_sum)
    nuc_frac[is.na(nuc_frac)] = 0
    
    ## write output to gzipped table
    print(paste('Nuclear fraction output to:', nuclearFractionEstimates_fn[sample]))
    nuclearFraction_df = 
      data.frame(barcodes = barcodes, nuclear_fraction = nuc_frac) %>% 
      write_tsv(nuclearFractionEstimates_fn[sample])
  }
}


##############################################
# 4) Load the snRNA-seq with Seurat functions
## find folders w/ ambient RNA-corrected coutns outputs are
STARsolo_fn = STARsoloDIR %>% 
  list.dirs(full.names = T,recursive = T) %>% str_subset('SoupX_counts$')
names(STARsolo_fn) = ss(STARsolo_fn,"(STARsolo_out/)|(.Solo.out)",2)

## loops over each file name, runs the Read10X function
dataList <- lapply(STARsolo_fn, Read10X, strip.suffix = TRUE)

## Initialize the Seurat object with the raw (non-normalized data).
## loops over both each dataList object and the name of the snRNA data to 
## create a SeuratObject, one for each 10x sample
objList <- mapply(CreateSeuratObject, min.cells = 3, min.features = 200,
                  counts = dataList, project = names(dataList))


###################################
# 5) compute QC metrics per sample
## compute SCDS doublet scores 
objList = lapply(objList, function(obj){
  ## convert to SingleCellExperiment Object first
  sce = as.SingleCellExperiment(obj)
  ## compute hybrid SCDS doublet score
  sce <- cxds_bcds_hybrid(sce,list("retRes"=TRUE))
  ## add score back to Seurat object, high score more likely doublet
  obj$scds.hybrid_score = colData(sce)$hybrid_score
  obj$scds.keep = ifelse(obj$scds.hybrid_score < 1.0, 'keep', 'doublet')
return(obj)
})

## compute miQC quality scores
objList = lapply(objList, function(obj){
  ## compute % of gene counts from mitochondrial genes
  obj[["percent.mt"]] <- PercentageFeatureSet(object = obj, pattern = "^MT-")
  ## estimate cells w/ high score likely "compromised"/low QC cells,
  obj <- RunMiQC(obj, percent.mt = "percent.mt", nFeature_RNA = "nFeature_RNA", 
                 posterior.cutoff = 0.75, model.slot = "flexmix_model")
  return(obj)
})

## add in the nuclear fraction per cell, for DropletQC later on
objList = lapply(objList, function(obj){
  sample = unique(obj$orig.ident)[1]
  print(paste0('Getting nuclear fraction for ', sample,'.'))
  
  ## read in the nuclear fractions for this sample
  nuc_frac_fn = STARsoloDIR %>%
    list.dirs(full.names = T,recursive = T) %>% str_subset('GeneFull$') %>% 
    str_subset(as.character(sample)) %>% file.path('DropletQC_NuclearFraction.txt.gz')
  print(paste0('NuclearFraction from ', nuc_frac_fn,'.'))
  nf = nuc_frac_fn %>% read_tsv(show_col_types = FALSE) %>%
    filter(barcodes %in% colnames(obj)) %>% 
    column_to_rownames('barcodes')
  
  ## add score back to Seurat object, high score more likely doublet
  obj$dropletQC.nucFrac = nf[colnames(obj),'nuclear_fraction']
  return(obj)
})

#######################################################################
# 6) perform SCTransform and PCA embedding to be integrated in full dataset
## SCTransform on each sample separately
objList = lapply(objList, SCTransform, method = "glmGamPoi", 
                 vars.to.regress = "percent.mt",verbose = TRUE)

## compute PCA on each SCT object separately
objList = lapply(objList, RunPCA, verbose = FALSE)


####################################
# 7) save objects and write to file
save_fn = here('data/raw_data/Seurat_objects', 
                 paste0('STARsolo_SoupX_rawCounts_',names(dataList), '.rds'))
mapply(saveRDS, object = objList, file = save_fn)


