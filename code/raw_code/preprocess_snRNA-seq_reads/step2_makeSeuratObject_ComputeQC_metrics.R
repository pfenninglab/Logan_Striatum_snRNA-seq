## conda activate r4
## packages for data table processing 
library(here)
library(tidyverse)

## main Seurat package snRNA-seq pacakges
library(Seurat)
library(SeuratDisk)
library(SeuratWrappers)
library(future)

## packages for QC metric computation
library(SingleCellExperiment)
library(scds)
library(flexmix)
library(SoupX)

ss <- function(x, pattern, slot = 1, ...) { 
  sapply(strsplit(x = x, split = pattern, ...), '[', slot) }
options(stringsAsFactors = F)
options(repr.plot.width=11, repr.plot.height=8.5)

#########################################################
# 0) Seurat uses the future package for parallelization
## set to be parallel over 8 cores
plan("multicore", workers = 8)
options(future.globals.maxSize = 20000 * 1024^2)
options(future.rng.onMisuse = 'ignore')

##########################################
# 1) find the files generated by STARsolo 
# files are both raw counts and filtered counts by STARsolo
# these folders should have a barcodes.tsv, genes.tsv, and matrix.mtx files
STARsoloDIR= 'data/raw_data/STARsolo_out'

## find folders where filtered outputs are
STARsolo_filtered_fn = STARsoloDIR %>% 
  list.dirs(full.names = T,recursive = T) %>%
  str_subset('filtered$')

## find folders where raw outputs are
STARsolo_raw_fn = STARsoloDIR %>% 
  list.dirs(full.names = T,recursive = T) %>%
  str_subset('raw$')

## name the file paths by string matching with regex patterns
## this gets sample names such as C-13114, based on folder naming convention 
names(STARsolo_filtered_fn) = ss(STARsolo_filtered_fn,"(STARsolo_out/)|(.Caudate.Solo.out)",2)
head(STARsolo_filtered_fn)

names(STARsolo_raw_fn) = ss(STARsolo_raw_fn,"(STARsolo_out/)|(.Caudate.Solo.out)",2)
head(STARsolo_raw_fn)

## look at files in these directories
(tmp_fn = sapply(c(STARsolo_filtered_fn, STARsolo_raw_fn), list.files, full.names = T))
## files should show barcodes.tsv.gz, features.tsv.gz, and matrix.mtx.gz
for(file in unlist(tmp_fn)){
  ## if not gzipped, we can do that now
  if(!grepl('.gz$', file)) R.utils::gzip(file)
}


##################################
# 2) Ambient RNA removal by SoupX
for(sample in names(STARsolo_raw_fn)){
  de_soup_counts_dn = gsub('filtered','SoupX_counts', STARsolo_filtered_fn[sample])
  if(dir.exists(de_soup_counts_dn)){
    print(paste('SoupX already computed:', de_soup_counts_dn))
  } else{
    print(paste('Reading in counts for:', sample,'.'))
    ## read in the filtered counts and raw counts
    ## https://rawcdn.githack.com/constantAmateur/SoupX/204b602418df12e9fdb4b68775a8b486c6504fe4/inst/doc/pbmcTutorial.html
    toc = Seurat::Read10X(STARsolo_filtered_fn[sample])
    tod = Seurat::Read10X(STARsolo_raw_fn[sample])
    
    ## routine Seurat clustering for SoupX, will be redone later
    ## https://satijalab.org/seurat/articles/essential_commands.html
    print(paste('Processing counts for SoupX.'))
    obj <- CreateSeuratObject(counts = toc) %>%
      NormalizeData(verbose = F) %>%
      FindVariableFeatures(verbose = F) %>%
      ScaleData(verbose = F) %>%
      RunPCA(verbose = F) %>%
      FindNeighbors(verbose = F) %>%
      FindClusters(algorithm = 2, resolution = 0.5, verbose = F)

    ## give SoupX the filtered counts, raw counts, and highly required basic clustering
    print(paste('Estimating ambient RNA w/ SoupX.'))
    sc = SoupChannel(tod, toc)
    sc = setClusters(sc, setNames(obj$seurat_clusters, colnames(obj)))
    sc = autoEstCont(sc, doPlot = F)
    out = adjustCounts(sc, roundToInt=TRUE)
    
    ## adjust filtered cell counts for ambient RNA
    print(paste('Corrected counts output to:', de_soup_counts_dn))
    write10xCounts(de_soup_counts_dn, out, barcodes = ss(colnames(out),'_',2), version = '3')
  }
}

##############################################
# 3) Load the snRNA-seq with Seurat functions
## find folders w/ ambient RNA-corrected coutns outputs are
STARsolo_fn = STARsoloDIR %>% 
  list.dirs(full.names = T,recursive = T) %>%
  str_subset('SoupX_counts$')
names(STARsolo_fn) = ss(STARsolo_fn,"(STARsolo_out/)|(.Caudate.Solo.out)",2)

## loops over each file name, runs the Read10X function
dataList <- lapply(STARsolo_fn, Read10X, strip.suffix = TRUE)

## Initialize the Seurat object with the raw (non-normalized data).
## loops over both each dataList object and the name of the snRNA data to 
## create a SeuratObject, one for each 10x sample
objList <- mapply(CreateSeuratObject, min.cells = 3, min.features = 200,
                  counts = dataList, project = names(dataList))

###################################
# 4) compute QC metrics per sample
## compute SCDS doublet scores 
objList = lapply(objList, function(obj){
  ## convert to SingleCellExperiment Object first
  sce = as.SingleCellExperiment(obj)
  ## compute hybrid SCDS doublet score
  sce <- cxds_bcds_hybrid(sce,list("retRes"=TRUE))
  ## add score back to Seurat object, high score more likely doublet
  obj$scds.hybrid_score = colData(sce)$hybrid_score
  obj$scds.keep = ifelse(obj$scds.hybrid_score < 1.0, 'keep', 'doublet')
return(obj)
})

## compute miQC quality scores
objList = lapply(objList, function(obj){
  ## compute % of gene counts from mitochondrial genes
  obj[["percent.mt"]] <- PercentageFeatureSet(object = obj, pattern = "^MT-")
  ## estimate cells w/ high score likely "compromised"/low QC cells,
  obj <- RunMiQC(obj, percent.mt = "percent.mt", nFeature_RNA = "nFeature_RNA", 
                 posterior.cutoff = 0.75, model.slot = "flexmix_model")
  return(obj)
})

#######################################################################
# 5) perform SCTransform and PCA embedding to be integrated in full dataset
## SCTransform on each sample separately
objList = lapply(objList, SCTransform, method = "glmGamPoi", 
                 vars.to.regress = "percent.mt",verbose = TRUE)

## compute PCA on each SCT object separately
objList = lapply(objList, RunPCA, verbose = FALSE)

####################################
# 6) save objects and write to file
save_fn = here('data/raw_data/Seurat_objects', 
                 paste0('STARsolo_SoupX_rawCounts_',names(dataList), '.rds'))
mapply(saveRDS, object = objList, file = save_fn)


